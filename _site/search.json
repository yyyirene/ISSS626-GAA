[
  {
    "objectID": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html",
    "href": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html",
    "title": "Take home Exercise03",
    "section": "",
    "text": "Setting the SceneThe Task\n\n\nHousing is an essential component of household wealth worldwide. Buying a housing has always been a major investment for most people. The price of housing is affected by many factors. Some of them are global in nature such as the general economy of a country or inflation rate. Others can be more specific to the properties themselves. These factors can be further divided to structural and locational factors. Structural factors are variables related to the property themselves such as the size, fitting, and tenure of the property. Locational factors are variables related to the neighbourhood of the properties such as proximity to childcare centre, public transport service and shopping centre.\nConventional, housing resale prices predictive models were built by using Ordinary Least Square (OLS) method. However, this method failed to take into consideration that spatial autocorrelation and spatial heterogeneity exist in geographic data sets such as housing transactions. With the existence of spatial autocorrelation, the OLS estimation of predictive housing resale pricing models could lead to biased, inconsistent, or inefficient results (Anselin 1998). In view of this limitation, Geographical Weighted Models were introduced to better calibrate predictive models for housing resale prices.\nIn this study, we focus on key residential areas—Jurong East, Woodlands, Yishun, Tampines, Kallang, and Queenstown—alongside HDB projects for 2024. This targeted approach aims to offer valuable insights for prospective homebuyers, helping them make well-informed decisions and better prepare for the housing market.\n\n\nIn this take-home exercise, we are required to calibrate a predictive model to predict HDB resale prices between July-September 2024 by using HDB resale transaction records in 2023."
  },
  {
    "objectID": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html#predicting-hdb-resale-prices-with-geographically-weighted-machine-learning-methods",
    "href": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html#predicting-hdb-resale-prices-with-geographically-weighted-machine-learning-methods",
    "title": "Take home Exercise03",
    "section": "",
    "text": "Setting the SceneThe Task\n\n\nHousing is an essential component of household wealth worldwide. Buying a housing has always been a major investment for most people. The price of housing is affected by many factors. Some of them are global in nature such as the general economy of a country or inflation rate. Others can be more specific to the properties themselves. These factors can be further divided to structural and locational factors. Structural factors are variables related to the property themselves such as the size, fitting, and tenure of the property. Locational factors are variables related to the neighbourhood of the properties such as proximity to childcare centre, public transport service and shopping centre.\nConventional, housing resale prices predictive models were built by using Ordinary Least Square (OLS) method. However, this method failed to take into consideration that spatial autocorrelation and spatial heterogeneity exist in geographic data sets such as housing transactions. With the existence of spatial autocorrelation, the OLS estimation of predictive housing resale pricing models could lead to biased, inconsistent, or inefficient results (Anselin 1998). In view of this limitation, Geographical Weighted Models were introduced to better calibrate predictive models for housing resale prices.\nIn this study, we focus on key residential areas—Jurong East, Woodlands, Yishun, Tampines, Kallang, and Queenstown—alongside HDB projects for 2024. This targeted approach aims to offer valuable insights for prospective homebuyers, helping them make well-informed decisions and better prepare for the housing market.\n\n\nIn this take-home exercise, we are required to calibrate a predictive model to predict HDB resale prices between July-September 2024 by using HDB resale transaction records in 2023."
  },
  {
    "objectID": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html#the-data",
    "href": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html#the-data",
    "title": "Take home Exercise03",
    "section": "1.The Data",
    "text": "1.The Data\n\nAspatial dataset:\n\nHDB Resale data: a list of HDB resale transacted prices in Singapore from Jan 2017 onwards. It is in csv format which can be downloaded from Data.gov.sg.\n\nGeospatial dataset:\n\nMP14_SUBZONE_WEB_PL: a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from Data.gov.sg\n\nLocational factors with geographic coordinates:\n\nDownloaded from Data.gov.sg.\n\nEldercare data is a list of eldercare in Singapore. It is in shapefile format.\nHawker Centre data is a list of hawker centres in Singapore. It is in geojson format.\nParks data is a list of parks in Singapore. It is in geojson format.\nSupermarket data is a list of supermarkets in Singapore. It is in geojson format.\nCHAS clinics data is a list of CHAS clinics in Singapore. It is in geojson format.\nKindergartens data is a list of kindergartens in Singapore. It is in geojson format.\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf we need to display the prediction results on a web application or map, GeoJSON is more convenient because most web map libraries (such as Leaflet and Mapbox) directly support GeoJSON data.\nWhen visualizing the analysis results, we can directly export them to GeoJSON, which is convenient for displaying the prediction results on various online map applications.\n\n\n\nDownloaded from Datamall.lta.gov.sg.\n\nMRT data is a list of MRT/LRT stations in Singapore with the station names and codes. It is in shapefile format.\nBus stops data is a list of bus stops in Singapore. It is in shapefile format.\n\n\nLocational factors without geographic coordinates:\n\nRetrieved/Scraped from other sources\n\nCBD coordinates obtained from Google.\nShopping malls data is a list of Shopping malls in Singapore obtained from Wikipedia.\nGood primary schools is a list of primary schools that are ordered in ranking in terms of popularity and this can be found at Local Salary Forum."
  },
  {
    "objectID": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html#getting-start",
    "href": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html#getting-start",
    "title": "Take home Exercise03",
    "section": "2.Getting start",
    "text": "2.Getting start\n\nInstalling and Loading R packages\n\npacman::p_load(sf, spdep, GWmodel, SpatialML, tmap, rsample, Metrics, tidyverse,stringr,httr, jsonlite, rvest,knitr,kableExtra)\n\n\n\nImporting Resale Data\nUsing HDB resale transaction records in 2023 and the future data from July to September for comparison.\n\nresale &lt;- read_csv(\"data/rawdata/aspatial/resale.csv\") %&gt;%\n  filter((month &gt;= \"2023-01\" & month &lt; \"2024-01\") | \n         (month &gt;= \"2024-07\" & month &lt;= \"2024-09\"))\n\nRows: 192234 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): month, town, flat_type, block, street_name, storey_range, flat_mode...\ndbl (3): floor_area_sqm, lease_commence_date, resale_price\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nData Processing for HDB Resale\nThe specific steps are as follows:\n\nCreate a new column address: Combine the address information into a new column address by splicing the block and street_name columns.\nExtract and convert the remaining lease time: Extract the year and month from the remaining_lease column and create integer columns remaining_lease_yr and remaining_lease_mth to represent the remaining lease years and months respectively.\nRemove columns that are no longer needed: Delete the block, street_name, and remaining_lease columns because they have been integrated or decomposed into other variables.\nClean the flat_type column: Remove the word “ROOM” in the flat_type column and represent the room type as a pure number.\nConvert the resale_price column to an integer: Convert the data type of the resale price resale_price column to an integer.\nSeparate the storey_range column: Split the floor range information from the storey_range column into two columns, min_storey and max_storey, and convert them to integer type.\nCalculate the middle value of the floor: Create a storey_mid column, calculate the average of min_storey and max_storey, and represent the middle number of the floor.\nRemove redundant floor columns: Delete the min_storey and max_storey columns because their middle values ​​are already represented by the storey_mid column.\n\n\nresale_tidy &lt;- resale %&gt;%\n  mutate(address = paste(block,street_name)) %&gt;% \n  mutate(remaining_lease_yr = as.integer(    \n    str_sub(remaining_lease, 0, 2)))%&gt;%  \n  mutate(remaining_lease_mth = as.integer(\n    str_sub(remaining_lease, 9, 11))) %&gt;% \n  mutate(total_remaining_months = remaining_lease_yr * 12 + remaining_lease_mth)  %&gt;% \n  select(-block, -street_name,-remaining_lease,-remaining_lease_yr,-remaining_lease_mth) %&gt;% \n  mutate(flat_type = str_replace(flat_type, \" ROOM\", \"\")) %&gt;% \n  mutate(resale_price = as.integer(resale_price)) %&gt;% \n  separate(storey_range, into = c(\"min_storey\", \"max_storey\"), sep = \" TO \", convert = TRUE) %&gt;%\n  mutate(storey_mid = (min_storey + max_storey) / 2) %&gt;%\n  select(-min_storey, -max_storey)     \n\n\n\nConvert into categorical variables\nFactor is a data type used to represent categorical variables. And they can store discrete, finite categories.\n\nresale_tidy$town &lt;- as.factor(resale_tidy$town)\n\nSee how many categories of the flat_type.\n\nunique(resale_tidy$flat_type)\n\n[1] \"2\"                \"3\"                \"4\"                \"5\"               \n[5] \"EXECUTIVE\"        \"MULTI-GENERATION\" \"1\"               \n\n\nSee how many categories of the flat_model.\n\nunique(resale_tidy$flat_model)\n\n [1] \"Improved\"               \"New Generation\"         \"Model A\"               \n [4] \"DBSS\"                   \"Standard\"               \"Apartment\"             \n [7] \"Simplified\"             \"Premium Apartment\"      \"Model A-Maisonette\"    \n[10] \"Maisonette\"             \"Model A2\"               \"Type S1\"               \n[13] \"Type S2\"                \"2-room\"                 \"Adjoined flat\"         \n[16] \"Terrace\"                \"Premium Apartment Loft\" \"Multi Generation\"      \n[19] \"Improved-Maisonette\"    \"3Gen\"                  \n\n\n\n\nNumerical categorical variables for flat_model.\n\nresale_tidy$flat_model_numeric &lt;- as.numeric(factor(resale_tidy$flat_model))\n\nfactor_levels &lt;- levels(factor(resale_tidy$flat_model))\nmapping &lt;- data.frame(Number = 1:length(factor_levels), Model = factor_levels)\nprint(mapping)\n\n   Number                  Model\n1       1                 2-room\n2       2                   3Gen\n3       3          Adjoined flat\n4       4              Apartment\n5       5                   DBSS\n6       6               Improved\n7       7    Improved-Maisonette\n8       8             Maisonette\n9       9                Model A\n10     10     Model A-Maisonette\n11     11               Model A2\n12     12       Multi Generation\n13     13         New Generation\n14     14      Premium Apartment\n15     15 Premium Apartment Loft\n16     16             Simplified\n17     17               Standard\n18     18                Terrace\n19     19                Type S1\n20     20                Type S2\n\n\n\n\nNumerical categorical variables flat_type.\n\nresale_tidy$flat_type_numeric &lt;- as.numeric(factor(resale_tidy$flat_type))\n\nfactor_levels2 &lt;- levels(factor(resale_tidy$flat_type))\nmapping &lt;- data.frame(Number = 1:length(factor_levels2), Model = factor_levels2)\nprint(mapping)\n\n  Number            Model\n1      1                1\n2      2                2\n3      3                3\n4      4                4\n5      5                5\n6      6        EXECUTIVE\n7      7 MULTI-GENERATION\n\n\n\nresale_tidy&lt;-resale_tidy %&gt;% select(-flat_type,-flat_model)\n\n\n\n\n\n\n\nNote\n\n\n\nAfter conversion to factors, the model can generate different coefficients for each category, which makes it easier to interpret the specific impact of each category on the result. For example, for a variable like “flat_model” (house model), the model can provide the impact of each house model on price, rather than simply encoding the house model.\n\n\n\n\nGetting coords\nWe firstly extract the unique address from dataset,which will be more quickly to get the result.\n\nadd_list &lt;- sort(unique(resale_tidy$address))\n\nUsing the code provided by Professor Kam ,which created the function to get the coordinates from onemap website.\n\n\nShow the code\nget_coords &lt;- function(add_list){\n  \n  # Create a data frame to store all retrieved coordinates\n  postal_coords &lt;- data.frame()\n    \n  for (i in add_list){\n    #print(i)\n\n    r &lt;- GET('https://www.onemap.gov.sg/api/common/elastic/search?',\n           query=list(searchVal=i,\n                     returnGeom='Y',\n                     getAddrDetails='Y'))\n    data &lt;- fromJSON(rawToChar(r$content))\n    found &lt;- data$found\n    res &lt;- data$results\n    \n    # Create a new data frame for each address\n    new_row &lt;- data.frame()\n    \n    # If single result, append \n    if (found == 1){\n      postal &lt;- res$POSTAL \n      lat &lt;- res$LATITUDE\n      lng &lt;- res$LONGITUDE\n      new_row &lt;- data.frame(address= i, \n                            postal = postal, \n                            latitude = lat, \n                            longitude = lng)\n    }\n    \n    # If multiple results, drop NIL and append top 1\n    else if (found &gt; 1){\n      # Remove those with NIL as postal\n      res_sub &lt;- res[res$POSTAL != \"NIL\", ]\n      \n      # Set as NA first if no Postal\n      if (nrow(res_sub) == 0) {\n          new_row &lt;- data.frame(address= i, \n                                postal = NA, \n                                latitude = NA, \n                                longitude = NA)\n      }\n      \n      else{\n        top1 &lt;- head(res_sub, n = 1)\n        postal &lt;- top1$POSTAL \n        lat &lt;- top1$LATITUDE    # return x and y\n        lng &lt;- top1$LONGITUDE\n        new_row &lt;- data.frame(address= i, \n                              postal = postal, \n                              latitude = lat, \n                              longitude = lng)\n      }\n    }\n\n    else {\n      new_row &lt;- data.frame(address= i, \n                            postal = NA,  \n                            latitude = NA, # take care of any possible data \n                            longitude = NA)\n    }\n    \n    # Add the row\n    postal_coords &lt;- rbind(postal_coords, new_row)\n  }\n  return(postal_coords)\n}\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn this exercise,we mainly use the detail address to get the coordinate and there is another method,which is using the postal,and the result is also the similar.\n\n\nStart to get coordinates of each asset.\n\ncoords_resale2 &lt;- get_coords(add_list)\n\nNext saving and reading the data for later convenient analysis\n\nsaveRDS(coords_resale2, \"data/rds/coords_resale2.rds\")\n\n\ncoords_resale2 &lt;- readRDS(\"data/rds/coords_resale2.rds\")\n\n\nsaveRDS(coords_resale, \"data/rds/coords_resale.rds\")\n\n\ncoords_resale &lt;- readRDS(\"data/rds/coords_resale.rds\")\n\n\n\nIntegrate data by using left join\n\nresale_tidy &lt;- resale_tidy %&gt;%\n  left_join(coords_resale2, by = \"address\")\n\nDelete the useless postal columns\n\nresale_tidy2 &lt;- resale_tidy %&gt;%\n  select(-postal) \n\nHere we check that there is no coordinate information in the dataset ,so we manually add on and transfer into Singapore coordinate.\n\nprint(st_crs(resale_tidy2))\n\nCoordinate Reference System: NA\n\n\n\nresale_tidy2 &lt;- st_as_sf(resale_tidy2, coords = c(\"longitude\", \"latitude\"), crs = 4326) %&gt;%\n  st_transform(crs = 3414)\n\nNow we can see it is successfully converted.\n\nst_crs(resale_tidy2)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\nImporting Geospatial Data\n\nmpsz &lt;- st_read(dsn = \"data/rawdata/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/yangyayong/Downloads/学校文件/smu文件/Term 3/G/yyyirene/ISSS626-GAA/Take_home_Ex/Take_home_Ex03/data/rawdata/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\nImporting Locational factors :\nImporting Locational factors with geographic coordinates\n\neldercare &lt;- st_read(dsn = \"data/rawdata/geospatial\", layer = \"ELDERCARE\")   #meter\n\nReading layer `ELDERCARE' from data source \n  `/Users/yangyayong/Downloads/学校文件/smu文件/Term 3/G/yyyirene/ISSS626-GAA/Take_home_Ex/Take_home_Ex03/data/rawdata/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 133 features and 18 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14481.92 ymin: 28218.43 xmax: 41665.14 ymax: 46804.9\nProjected CRS: SVY21\n\nhawker_centres &lt;- st_read(\"data/rawdata/geospatial/HawkerCentresGEOJSON.geojson\")\n\nReading layer `HawkerCentresGEOJSON' from data source \n  `/Users/yangyayong/Downloads/学校文件/smu文件/Term 3/G/yyyirene/ISSS626-GAA/Take_home_Ex/Take_home_Ex03/data/rawdata/geospatial/HawkerCentresGEOJSON.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 125 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6974 ymin: 1.272716 xmax: 103.9882 ymax: 1.449017\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\nkindergartens &lt;- st_read(\"data/rawdata/geospatial/Kindergartens.geojson\")\n\nReading layer `Kindergartens' from data source \n  `/Users/yangyayong/Downloads/学校文件/smu文件/Term 3/G/yyyirene/ISSS626-GAA/Take_home_Ex/Take_home_Ex03/data/rawdata/geospatial/Kindergartens.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 448 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6887 ymin: 1.247759 xmax: 103.9717 ymax: 1.455452\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\nparks &lt;- st_read(\"data/rawdata/geospatial/Parks.geojson\")\n\nReading layer `Parks' from data source \n  `/Users/yangyayong/Downloads/学校文件/smu文件/Term 3/G/yyyirene/ISSS626-GAA/Take_home_Ex/Take_home_Ex03/data/rawdata/geospatial/Parks.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 430 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6929 ymin: 1.214491 xmax: 104.0538 ymax: 1.462094\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\nsupermarkets &lt;- st_read(\"data/rawdata/geospatial/SupermarketsGEOJSON.geojson\")\n\nReading layer `SupermarketsGEOJSON' from data source \n  `/Users/yangyayong/Downloads/学校文件/smu文件/Term 3/G/yyyirene/ISSS626-GAA/Take_home_Ex/Take_home_Ex03/data/rawdata/geospatial/SupermarketsGEOJSON.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 526 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6258 ymin: 1.24715 xmax: 104.0036 ymax: 1.461526\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\nchas_clinics &lt;- st_read(\"data/rawdata/geospatial/CHASclinics.geojson\") \n\nReading layer `CHASClinics' from data source \n  `/Users/yangyayong/Downloads/学校文件/smu文件/Term 3/G/yyyirene/ISSS626-GAA/Take_home_Ex/Take_home_Ex03/data/rawdata/geospatial/CHASClinics.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1193 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.5818 ymin: 1.016264 xmax: 103.9903 ymax: 1.456037\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\nBusStop &lt;- st_read(dsn = \"data/rawdata/geospatial\", layer = \"BusStop\") \n\nReading layer `BusStop' from data source \n  `/Users/yangyayong/Downloads/学校文件/smu文件/Term 3/G/yyyirene/ISSS626-GAA/Take_home_Ex/Take_home_Ex03/data/rawdata/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5166 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48285.52 ymax: 52983.82\nProjected CRS: SVY21\n\nMRT &lt;- st_read(dsn = \"data/rawdata/geospatial\", layer = \"RapidTransitSystemStation\") \n\nReading layer `RapidTransitSystemStation' from data source \n  `/Users/yangyayong/Downloads/学校文件/smu文件/Term 3/G/yyyirene/ISSS626-GAA/Take_home_Ex/Take_home_Ex03/data/rawdata/geospatial' \n  using driver `ESRI Shapefile'\n\n\nWarning in CPL_read_ogr(dsn, layer, query, as.character(options), quiet, : GDAL\nMessage 1: Non closed ring detected. To avoid accepting it, set the\nOGR_GEOMETRY_ACCEPT_UNCLOSED_RING configuration option to NO\n\n\nSimple feature collection with 230 features and 5 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 6068.209 ymin: 27478.44 xmax: 45377.5 ymax: 47913.58\nProjected CRS: SVY21\n\n\nConvert a multipoint object (MULTIPOINT) to a single point (POINT) ,which is convenient for subsequent calculations\n\nMRT &lt;- st_cast(MRT, \"POINT\")\n\nWarning in st_cast.sf(MRT, \"POINT\"): repeating attributes for all\nsub-geometries for which they may not be constant\n\n\nImporting Locational factors without geographic coordinates\n\nGoodprimaryschool &lt;- read_csv(\"data/rawdata/aspatial/Goodprimaryschool.csv\") \n\nRows: 179 Columns: 1\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): school_name\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nShoppingmalls &lt;- read_csv(\"data/rawdata/aspatial/Shoppingmalls.csv\")\n\nRows: 174 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): mallname, malladdress\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nGetting coords for Good primary schoolGetting coords for Shopping malls\n\n\n\nadd_list&lt;- sort(unique(Goodprimaryschool$school_name))\n\n\ncoords_Goodprimaryschool &lt;- get_coords(add_list) \n\n\nsaveRDS(coords_Goodprimaryschool, \"data/rds/coords_Goodprimaryschool.rds\")\n\n\ncoords_Goodprimaryschool &lt;- readRDS(\"data/rds/coords_Goodprimaryschool.rds\")\n\n\nGoodprimaryschool &lt;- st_as_sf(coords_Goodprimaryschool, coords = c(\"longitude\", \"latitude\"), crs = 4326) %&gt;%\n  st_transform(crs = 3414)\n\n\nst_crs(Goodprimaryschool)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nadd_list&lt;- sort(unique(Shoppingmalls$malladdress))\n\n\ncoords_Shoppingmalls &lt;- get_coords(add_list)\n\n\nsaveRDS(coords_Shoppingmalls, \"data/rds/coords_Shoppingmalls.rds\")\n\n\ncoords_Shoppingmalls &lt;- readRDS(\"data/rds/coords_Shoppingmalls.rds\")\n\n\nShoppingmalls &lt;- st_as_sf(coords_Shoppingmalls, coords = c(\"longitude\", \"latitude\"), crs = 4326) %&gt;%\n  st_transform(crs = 3414)\n\n\nst_crs(Shoppingmalls)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\n\n\nData Wrangling\nApply Spatial Jitter:\n\n\n\n\n\n\nNote\n\n\n\nWhen using GWmodel to calibrate explanatory or predictive models, it is very important to ensure that there are no overlapping point features\nBy adding a slight jitter, we make the points more distinguishable in maps or plots.\n\n\nThe code chunk below is used to check if there are overlapping point features.\n\noverlapping_points &lt;- resale_tidy2 %&gt;%\n  mutate(overlap = lengths(st_equals(., .)) &gt; 1)\n\nFrom the result ,there are indeed overlapping points in the dataset.\nSo in the code chunk below, st_jitter() of sf package is used to move the point features by 0.05m to avoid overlapping point features.\n\nresale_tidy2 &lt;- resale_tidy2 %&gt;% st_jitter(amount = .05)\n\nAccording to the Google provided,the Singapore’s CBD coordinate and we transfer into Singapore projection\n\ncbd &lt;- st_sfc(st_point(c(103.851959, 1.283850)), crs = 3414)\n\nCalculate Distances: Use st_distance() to calculate the Euclidean distance between each property and the target locations.\n\nelders &lt;- st_transform(eldercare, crs = 3414)\nhawkers &lt;- st_transform(hawker_centres, crs = 3414)\nparks &lt;- st_transform(parks, crs = 3414)\nsupermarkets &lt;- st_transform(supermarkets, crs = 3414)\nchas_clinics &lt;- st_transform(chas_clinics, crs = 3414)\nMRT &lt;- st_transform(MRT, crs = 3414)\n\n\n\nCompute the distance between properties and facilities:\n\nresale_tidy3 &lt;- resale_tidy2 %&gt;%\n  mutate(\n    dist_to_elders = st_distance(., elders) %&gt;% apply(1, min),\n    dist_to_hawkers = st_distance(., hawkers) %&gt;% apply(1, min),\n    dist_to_parks = st_distance(., parks) %&gt;% apply(1, min),\n    dist_to_supermarkets = st_distance(., supermarkets) %&gt;% apply(1, min),\n    dist_to_chas_clinics = st_distance(., chas_clinics) %&gt;% apply(1, min),\n    dist_to_cbd = st_distance(., cbd) %&gt;% apply(1, min),\n    dist_to_Shoppingmalls = st_distance(.,Shoppingmalls ) %&gt;% apply(1, min),\n    dist_to_MRT = st_distance(.,MRT ) %&gt;% apply(1, min),\n    dist_to_Goodprimaryschool = st_distance(.,Goodprimaryschool ) %&gt;% apply(1, min)\n    \n  )\n\nNow we can see the result as below :\n\nNote that the units are all meter.\nNext saving and reading the data for later convenient analysis\n\nsaveRDS(resale_tidy3, \"data/rds/resale_tidy3.rds\")\n\n\nresale_tidy3 &lt;- readRDS(\"data/rds/resale_tidy3.rds\")\n\n\n\nSelect the target area\n\nresale_tidy4 &lt;- resale_tidy3 %&gt;%\n  filter(town %in% c(\"JURONG EAST\", \"WOODLANDS\", \"YISHUN\", \"TAMPINES\", \"KALLANG/WHAMPOA\", \"QUEENSTOWN\")) %&gt;% \n  filter(flat_type_numeric %in% c(3, 4, 5)) %&gt;%\n  select(-town, -address)\n\n\n\nPotting the target area\n\ntmap_options(check.and.fix = TRUE)\n\nmpsz &lt;- st_make_valid(mpsz)\n\nstudy_areas &lt;- c(\"JURONG EAST\", \"WOODLANDS\", \"YISHUN\", \"TAMPINES\", \"KALLANG\", \"QUEENSTOWN\")\n\nmpsz_filtered &lt;- mpsz %&gt;%\n  filter(PLN_AREA_N %in% study_areas)\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(mpsz) +\n  tm_borders(col = \"gray80\", lwd = 0.5) +  \n  tm_shape(mpsz_filtered) +\n  tm_polygons(col = \"PLN_AREA_N\", palette = \"Set3\", border.col = \"black\") +  \n  tm_text(\"PLN_AREA_N\", size = 0.7, remove.overlap = TRUE, col = \"black\") +   \n  tm_layout(title = \"Map of Study Areas\",\n            legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\nCounting numbers of facilities-point in Buffering area\nBuffering\nBefore buffering,it is import to check and transform into the same crs.\n\nBusStop &lt;- BusStop %&gt;% st_transform(crs = 3414)\n\n\nkindergartens &lt;- kindergartens %&gt;% st_transform(crs = 3414)\n\n\nst_crs(kindergartens)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\nst_crs(BusStop)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\nbuffer_350m &lt;- st_buffer(resale_tidy4, dist = 350) \nbuffer_1000m &lt;- st_buffer(resale_tidy4, dist = 1000)\n\n\n\nPlot the newly created buffers and the assets.\n\n# Set tmap to static mode\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n# Create the map with multiple layers\ntm_shape(mpsz) +\n  tm_borders() +\n  tm_shape(buffer_350m) +\n  tm_polygons() +\n  tm_shape(resale_tidy4) +\n  tm_dots()\n\n\n\n\n\n\n\n\n\n# Set tmap to static mode\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n# Create the map with multiple layers\ntm_shape(mpsz) +\n  tm_borders() +\n  tm_shape(buffer_1000m) +\n  tm_polygons() +\n  tm_shape(resale_tidy4) +\n  tm_dots()\n\n\n\n\n\n\n\n\n\n\nCount number of points within a distance\n\nbuffer_350m$BusStop_count &lt;- lengths(st_intersects(buffer_350m, BusStop))\n\n\nbuffer_1000m$kindergartens_count&lt;- lengths(st_intersects(buffer_1000m, kindergartens))\n\n\n\nAdding the new features into the dataset.\n\nresale_tidy5 &lt;- resale_tidy4 %&gt;%\n  mutate(\n    BusStop_within_350m = buffer_350m$BusStop_count,\n    Kindergartens_within_1000m = buffer_1000m$kindergartens_count\n  )\n\nThe result show as below:\n\nIn this study,we first select the train and test data in 2023 for model training and also select the future data 2024 for later predict comparison.\nThen we did not consider the time influence to the house price,and we remove the time variables.\n\nresale_tidy5_future &lt;- resale_tidy5 %&gt;%\n  filter(month &gt;= \"2024-07\" & month &lt;= \"2024-09\") %&gt;% select(-month)\n\n\nresale_tidy5 &lt;- resale_tidy5 %&gt;% filter(month &gt;= \"2023-01\" & month &lt; \"2024-01\") %&gt;% select(-month)\n\n\nsaveRDS(resale_tidy5, \"data/rds/resale_tidy5.rds\")\n\n\nresale_tidy5 &lt;- readRDS(\"data/rds/resale_tidy5.rds\")"
  },
  {
    "objectID": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html#computing-correlation-matrix",
    "href": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html#computing-correlation-matrix",
    "title": "Take home Exercise03",
    "section": "3.Computing Correlation Matrix",
    "text": "3.Computing Correlation Matrix\nBefore loading the predictors into a predictive model, it is always a good practice to use correlation matrix to examine if there is sign of multicolinearity.\n\nresale_tidy5_nogeo &lt;- resale_tidy5 %&gt;%\n  st_drop_geometry() \n\nData type checking\n\nsapply(resale_tidy5_nogeo, class)\n\n            floor_area_sqm        lease_commence_date \n                 \"numeric\"                  \"numeric\" \n              resale_price     total_remaining_months \n                 \"integer\"                  \"numeric\" \n                storey_mid         flat_model_numeric \n                 \"numeric\"                  \"numeric\" \n         flat_type_numeric             dist_to_elders \n                 \"numeric\"                  \"numeric\" \n           dist_to_hawkers              dist_to_parks \n                 \"numeric\"                  \"numeric\" \n      dist_to_supermarkets       dist_to_chas_clinics \n                 \"numeric\"                  \"numeric\" \n               dist_to_cbd      dist_to_Shoppingmalls \n                 \"numeric\"                  \"numeric\" \n               dist_to_MRT  dist_to_Goodprimaryschool \n                 \"numeric\"                  \"numeric\" \n       BusStop_within_350m Kindergartens_within_1000m \n                 \"integer\"                  \"integer\" \n\n\nReplace NA values with 0 in both numeric and integer columns\n\nresale_tidy5_nogeo &lt;- resale_tidy5_nogeo %&gt;% \n  dplyr::mutate(across(where(~ is.numeric(.) || is.integer(.)), ~ replace_na(., 0)))\n\nGenerate correlation plot using only numeric and integer columns\n\ncorrplot::corrplot(cor(resale_tidy5_nogeo), \n                   diag = FALSE, \n                   order = \"AOE\",\n                   tl.pos = \"td\", \n                   tl.cex = 0.5, \n                   method = \"number\", \n                   type = \"upper\")\n\n\n\n\n\n\n\n\nFind correlation coefficients greater than 0.8 or less than -0.8 (excluding the 1s on the diagonal)\n\ncor_matrix &lt;- cor(resale_tidy5_nogeo)\n\nhigh_corr &lt;- which(abs(cor_matrix) &gt; 0.8 & abs(cor_matrix) &lt; 1, arr.ind = TRUE)\n\nif (nrow(high_corr) &gt; 0) {\n  cat(\"There are pairs of variables with correlation coefficients greater than 0.8 or less than -0.8:\\n\")\n  for (i in 1:nrow(high_corr)) {\n    cat(rownames(cor_matrix)[high_corr[i, \"row\"]], \"and\", colnames(cor_matrix)[high_corr[i, \"col\"]],\n        \"The correlation coefficient is:\", cor_matrix[high_corr[i, \"row\"], high_corr[i, \"col\"]], \"\\n\")\n  }\n} else {\n  cat(\"There are no variable pairs with correlation coefficients greater than 0.8 or less than -0.8。\\n\")\n}\n\nThere are pairs of variables with correlation coefficients greater than 0.8 or less than -0.8:\nflat_type_numeric and floor_area_sqm The correlation coefficient is: 0.9368229 \nfloor_area_sqm and flat_type_numeric The correlation coefficient is: 0.9368229 \n\n\nFrom the result ,we decide to remove : floor_area_sqm and lease_commence_date\n\nresale_tidy5_nogeo &lt;- resale_tidy5_nogeo %&gt;% select(-floor_area_sqm,-lease_commence_date)\n\nCheck whether we have removed the high relevant variables.\n\ncor_matrix &lt;- cor(resale_tidy5_nogeo)\n\n# Find correlation coefficients greater than 0.8 or less than -0.8 (excluding the 1s on the diagonal)\nhigh_corr &lt;- which(abs(cor_matrix) &gt; 0.8 & abs(cor_matrix) &lt; 1, arr.ind = TRUE)\n\nif (nrow(high_corr) &gt; 0) {\n  cat(\"There are pairs of variables with correlation coefficients greater than 0.8 or less than -0.8:\\n\")\n  for (i in 1:nrow(high_corr)) {\n    cat(rownames(cor_matrix)[high_corr[i, \"row\"]], \"and\", colnames(cor_matrix)[high_corr[i, \"col\"]],\n        \"The correlation coefficient is:\", cor_matrix[high_corr[i, \"row\"], high_corr[i, \"col\"]], \"\\n\")\n  }\n} else {\n  cat(\"There are no variable pairs with correlation coefficients greater than 0.8 or less than -0.8。\\n\")\n}\n\nThere are no variable pairs with correlation coefficients greater than 0.8 or less than -0.8。\n\n\nRemoving the highest correlation coefficients variables from the dataset.\n\nresale_tidy6 &lt;- resale_tidy5 %&gt;% select(-floor_area_sqm,-lease_commence_date)\n\n\nsummary(resale_tidy6)\n\n  resale_price     total_remaining_months   storey_mid    flat_model_numeric\n Min.   : 150000   Min.   : 506.0         Min.   : 2.00   Min.   : 2.000    \n 1st Qu.: 430000   1st Qu.: 730.0         1st Qu.: 5.00   1st Qu.: 6.000    \n Median : 528000   Median : 850.0         Median : 8.00   Median : 9.000    \n Mean   : 545977   Mean   : 867.6         Mean   : 8.31   Mean   : 9.539    \n 3rd Qu.: 620000   3rd Qu.:1071.0         3rd Qu.:11.00   3rd Qu.:11.000    \n Max.   :1300888   Max.   :1154.0         Max.   :47.00   Max.   :18.000    \n                   NA's   :520                                              \n flat_type_numeric          geometry    dist_to_elders      dist_to_hawkers  \n Min.   :3.000     POINT        :6739   Min.   :   0.0242   Min.   :  40.42  \n 1st Qu.:3.000     epsg:3414    :   0   1st Qu.: 322.9330   1st Qu.: 407.21  \n Median :4.000     +proj=tmer...:   0   Median : 545.4370   Median : 640.19  \n Mean   :3.948                          Mean   : 683.7001   Mean   : 722.19  \n 3rd Qu.:4.000                          3rd Qu.: 918.6596   3rd Qu.: 978.59  \n Max.   :5.000                          Max.   :2787.0916   Max.   :2281.50  \n                                                                             \n dist_to_parks     dist_to_supermarkets dist_to_chas_clinics  dist_to_cbd   \n Min.   :  60.03   Min.   :   0.0043    Min.   :  0.0048     Min.   :37265  \n 1st Qu.: 517.00   1st Qu.: 163.9752    1st Qu.:105.2877     1st Qu.:46518  \n Median : 780.76   Median : 253.3517    Median :163.8141     Median :52887  \n Mean   : 943.64   Mean   : 289.2077    Mean   :175.9627     Mean   :50621  \n 3rd Qu.:1324.09   3rd Qu.: 366.9664    3rd Qu.:234.3876     3rd Qu.:54069  \n Max.   :2411.75   Max.   :1451.8109    Max.   :663.8865     Max.   :56689  \n                                                                            \n dist_to_Shoppingmalls  dist_to_MRT      dist_to_Goodprimaryschool\n Min.   :   0.0502     Min.   :  20.56   Min.   :  43.83          \n 1st Qu.: 432.3296     1st Qu.: 352.14   1st Qu.: 233.14          \n Median : 636.8068     Median : 538.76   Median : 379.55          \n Mean   : 681.2412     Mean   : 597.72   Mean   : 443.87          \n 3rd Qu.: 897.0554     3rd Qu.: 799.33   3rd Qu.: 565.47          \n Max.   :1732.2770     Max.   :1973.05   Max.   :2081.76          \n                                                                  \n BusStop_within_350m Kindergartens_within_1000m\n Min.   : 0.000      Min.   : 0.000            \n 1st Qu.: 6.000      1st Qu.: 4.000            \n Median : 8.000      Median : 5.000            \n Mean   : 7.859      Mean   : 5.943            \n 3rd Qu.:10.000      3rd Qu.: 8.000            \n Max.   :16.000      Max.   :15.000            \n                                               \n\n\n\n\n\n\n\n\nNote\n\n\n\nThe print report above reveals that variables BusStop_within_350m,Kindergartens_within_1000m are consist of 0 values which is reasonable in this case ,because some HDB may not have BusStop and Kindergartens.\nHowever ,will notice there are some missing value in total_remaining_months and we use mean to replace them.\n\n\n\nresale_tidy6$total_remaining_months[is.na(resale_tidy6$total_remaining_months)] &lt;- mean(resale_tidy6$total_remaining_months, na.rm = TRUE)\n\n\nresale_tidy6_future &lt;- resale_tidy5_future %&gt;% select(-floor_area_sqm,-lease_commence_date)\n\nresale_tidy6_future$total_remaining_months[is.na(resale_tidy6_future$total_remaining_months)] &lt;- mean(resale_tidy6_future$total_remaining_months, na.rm = TRUE)"
  },
  {
    "objectID": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html#data-sampling",
    "href": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html#data-sampling",
    "title": "Take home Exercise03",
    "section": "4.Data Sampling",
    "text": "4.Data Sampling\n\nset.seed(1234) \nresale_split &lt;- initial_split(resale_tidy6, prop = 6.5/10,) \ntrain_data &lt;- training(resale_split) \ntest_data &lt;- testing(resale_split)\n\n\nsaveRDS(train_data, \"data/rds/train_data.rds\")\nsaveRDS(test_data, \"data/rds/test_data.rds\")\n\ntrain_data &lt;- readRDS(\"data/rds/train_data.rds\")\ntest_data &lt;- readRDS(\"data/rds/test_data.rds\")"
  },
  {
    "objectID": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html#building-a-non-spatial-multiple-linear-regression",
    "href": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html#building-a-non-spatial-multiple-linear-regression",
    "title": "Take home Exercise03",
    "section": "5.Building a non-spatial multiple linear regression",
    "text": "5.Building a non-spatial multiple linear regression\n\nprice_mlr &lt;- lm(resale_price ~ total_remaining_months +\n                  storey_mid + flat_model_numeric +\n                  flat_type_numeric + dist_to_elders + dist_to_hawkers +\n                  dist_to_parks + dist_to_supermarkets + dist_to_chas_clinics + \n                  dist_to_cbd + dist_to_Shoppingmalls +\n                  dist_to_MRT + dist_to_Goodprimaryschool +BusStop_within_350m+\n                  Kindergartens_within_1000m,\n                data=train_data)\nsummary(price_mlr)\n\n\nCall:\nlm(formula = resale_price ~ total_remaining_months + storey_mid + \n    flat_model_numeric + flat_type_numeric + dist_to_elders + \n    dist_to_hawkers + dist_to_parks + dist_to_supermarkets + \n    dist_to_chas_clinics + dist_to_cbd + dist_to_Shoppingmalls + \n    dist_to_MRT + dist_to_Goodprimaryschool + BusStop_within_350m + \n    Kindergartens_within_1000m, data = train_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-349377  -46190   -7675   39364  908630 \n\nCoefficients:\n                             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                 4.814e+04  1.828e+04   2.633  0.00850 ** \ntotal_remaining_months      3.850e+02  8.256e+00  46.630  &lt; 2e-16 ***\nstorey_mid                  5.833e+03  2.173e+02  26.844  &lt; 2e-16 ***\nflat_model_numeric         -5.503e+02  3.878e+02  -1.419  0.15596    \nflat_type_numeric           1.257e+05  1.778e+03  70.695  &lt; 2e-16 ***\ndist_to_elders             -3.652e+01  2.530e+00 -14.434  &lt; 2e-16 ***\ndist_to_hawkers            -9.553e+00  3.616e+00  -2.642  0.00827 ** \ndist_to_parks              -4.678e+01  2.360e+00 -19.825  &lt; 2e-16 ***\ndist_to_supermarkets       -3.147e+01  7.211e+00  -4.365 1.30e-05 ***\ndist_to_chas_clinics        3.569e+01  1.350e+01   2.643  0.00826 ** \ndist_to_cbd                -5.377e+00  3.032e-01 -17.733  &lt; 2e-16 ***\ndist_to_Shoppingmalls       4.488e+00  4.385e+00   1.023  0.30614    \ndist_to_MRT                -9.700e+01  4.304e+00 -22.540  &lt; 2e-16 ***\ndist_to_Goodprimaryschool   3.505e+01  4.683e+00   7.486 8.56e-14 ***\nBusStop_within_350m        -3.636e+03  4.879e+02  -7.451 1.11e-13 ***\nKindergartens_within_1000m  7.208e+03  4.671e+02  15.431  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 75930 on 4364 degrees of freedom\nMultiple R-squared:  0.7566,    Adjusted R-squared:  0.7558 \nF-statistic: 904.4 on 15 and 4364 DF,  p-value: &lt; 2.2e-16\n\n\nFrom the result,except flat_model,dist_to_hawkers,dist_to_chas_clinics,dist_to_Shoppingmalls,other variables are all significant .\nWith dist_to_elders,dist_to_parks,dist_to_supermarkets,dist_to_cbd,dist_to_MRT,BusStop_within_350m values get higher,the dependent variable will get smaller.For example the higher distance between CBD and the HDB ,the lower house price will be.\nThe R-squared and adjusted R-squared of the model are high, indicating that the model has strong explanatory power for the dependent variable.\n\nMulticollinearity check with VIF\n\nvif &lt;- performance::check_collinearity(price_mlr)\nkable(vif, \n      caption = \"Variance Inflation Factor (VIF) Results\") %&gt;%\n  kable_styling(font_size = 18) \n\n\nVariance Inflation Factor (VIF) Results\n\n\nTerm\nVIF\nVIF_CI_low\nVIF_CI_high\nSE_factor\nTolerance\nTolerance_CI_low\nTolerance_CI_high\n\n\n\n\ntotal_remaining_months\n1.473605\n1.419527\n1.534655\n1.213922\n0.6786077\n0.6516124\n0.7044600\n\n\nstorey_mid\n1.297002\n1.253526\n1.347933\n1.138860\n0.7710091\n0.7418767\n0.7977498\n\n\nflat_model_numeric\n1.158517\n1.124070\n1.202528\n1.076344\n0.8631726\n0.8315816\n0.8896244\n\n\nflat_type_numeric\n1.247064\n1.206708\n1.295299\n1.116720\n0.8018834\n0.7720225\n0.8287010\n\n\ndist_to_elders\n1.125374\n1.093420\n1.168257\n1.060836\n0.8885936\n0.8559757\n0.9145617\n\n\ndist_to_hawkers\n1.677701\n1.611681\n1.750846\n1.295261\n0.5960539\n0.5711526\n0.6204701\n\n\ndist_to_parks\n1.309632\n1.265380\n1.361263\n1.144391\n0.7635734\n0.7346121\n0.7902766\n\n\ndist_to_supermarkets\n1.432388\n1.380749\n1.491030\n1.196824\n0.6981348\n0.6706772\n0.7242444\n\n\ndist_to_chas_clinics\n1.289642\n1.246620\n1.340168\n1.135624\n0.7754093\n0.7461752\n0.8021690\n\n\ndist_to_cbd\n1.984741\n1.900952\n2.076323\n1.408808\n0.5038440\n0.4816207\n0.5260521\n\n\ndist_to_Shoppingmalls\n1.525338\n1.468215\n1.589431\n1.235046\n0.6555923\n0.6291561\n0.6810992\n\n\ndist_to_MRT\n1.597965\n1.536590\n1.666359\n1.264106\n0.6257960\n0.6001107\n0.6507915\n\n\ndist_to_Goodprimaryschool\n1.430574\n1.379043\n1.489111\n1.196066\n0.6990202\n0.6715418\n0.7251406\n\n\nBusStop_within_350m\n1.148264\n1.114562\n1.191881\n1.071571\n0.8708798\n0.8390098\n0.8972136\n\n\nKindergartens_within_1000m\n1.332344\n1.286706\n1.385246\n1.154272\n0.7505571\n0.7218933\n0.7771784\n\n\n\n\n\n\n\n\nplot(vif) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\nVariable `Component` is not in your data frame :/\n\n\n\n\n\n\n\n\n\nAll VIF values ​​are less than 5, and no further multicollinearity processing is required. Overall, this is a relatively healthy model and meets expectations in terms of collinearity detection."
  },
  {
    "objectID": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html#preparing-coordinates-data",
    "href": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html#preparing-coordinates-data",
    "title": "Take home Exercise03",
    "section": "6.Preparing coordinates data",
    "text": "6.Preparing coordinates data\nThe code chunk below extract the x,y coordinates of the full, training and test data sets.\n\ncoords &lt;- st_coordinates(resale_tidy6)\ncoords_train &lt;- st_coordinates(train_data)\ncoords_test &lt;- st_coordinates(test_data)\n\n\ntest_data_no &lt;- test_data %&gt;% st_drop_geometry()\n\nresale_tidy6_future_test_data &lt;- resale_tidy6_future %&gt;%\n  st_drop_geometry()\n\n\nDroping geometry field\nFirst, we will drop geometry column of the sf data.frame by using st_drop_geometry() of sf package.\n\ntrain_data &lt;- train_data %&gt;%\n  st_drop_geometry()"
  },
  {
    "objectID": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html#calibrating-random-forest-model",
    "href": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html#calibrating-random-forest-model",
    "title": "Take home Exercise03",
    "section": "7.Calibrating Random Forest Model",
    "text": "7.Calibrating Random Forest Model\n\nset.seed(1234)\nrf &lt;- ranger(resale_price ~ total_remaining_months +\n                  storey_mid + flat_model_numeric +\n                  flat_type_numeric + dist_to_elders + dist_to_hawkers +\n                  dist_to_parks + dist_to_supermarkets + dist_to_chas_clinics + \n                  dist_to_cbd + dist_to_Shoppingmalls +\n                  dist_to_MRT + dist_to_Goodprimaryschool +BusStop_within_350m+\n                  Kindergartens_within_1000m,\n                  data=train_data,\n             importance = 'impurity')\nrf\n\nRanger result\n\nCall:\n ranger(resale_price ~ total_remaining_months + storey_mid + flat_model_numeric +      flat_type_numeric + dist_to_elders + dist_to_hawkers + dist_to_parks +      dist_to_supermarkets + dist_to_chas_clinics + dist_to_cbd +      dist_to_Shoppingmalls + dist_to_MRT + dist_to_Goodprimaryschool +      BusStop_within_350m + Kindergartens_within_1000m, data = train_data,      importance = \"impurity\") \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      4380 \nNumber of independent variables:  15 \nMtry:                             3 \nTarget node size:                 5 \nVariable importance mode:         impurity \nSplitrule:                        variance \nOOB prediction error (MSE):       1550984845 \nR squared (OOB):                  0.9343029 \n\n\nOOB prediction error (MSE): 1546803122. The mean square error (MSE) of the out-of-bag data (OOB) is 1546803122. MSE is used to measure the prediction error of the model. The smaller the value, the more accurate the model’s prediction. OOB MSE provides an unbiased estimate of the generalization performance of the model.\nR squared (OOB): 0.93448 .The R squared value of the out-of-bag data is 0.93448. R squared values ​​close to 1 indicate that the model can explain the variance of the data well. In this case, 93.448% of the variance can be explained by the model, indicating that the model performs well on the out-of-bag data.\n\nExtracting feature importance\n\nimportance_rf &lt;- rf$variable.importance\n\nimportance_df &lt;- data.frame(Feature = names(importance_rf), \n                            Importance = importance_rf)\n\nlibrary(dplyr)\nimportance_df &lt;- importance_df %&gt;%\n  arrange(desc(Importance))\n\nprint(importance_df)\n\n                                              Feature   Importance\nflat_type_numeric                   flat_type_numeric 2.721029e+13\ntotal_remaining_months         total_remaining_months 1.555766e+13\ndist_to_cbd                               dist_to_cbd 1.199639e+13\nstorey_mid                                 storey_mid 1.095255e+13\nflat_model_numeric                 flat_model_numeric 7.970761e+12\ndist_to_MRT                               dist_to_MRT 4.552051e+12\ndist_to_Goodprimaryschool   dist_to_Goodprimaryschool 3.329271e+12\ndist_to_elders                         dist_to_elders 3.199836e+12\ndist_to_supermarkets             dist_to_supermarkets 3.138500e+12\ndist_to_hawkers                       dist_to_hawkers 3.126396e+12\ndist_to_parks                           dist_to_parks 3.004545e+12\ndist_to_Shoppingmalls           dist_to_Shoppingmalls 2.902800e+12\nKindergartens_within_1000m Kindergartens_within_1000m 2.010949e+12\ndist_to_chas_clinics             dist_to_chas_clinics 1.973228e+12\nBusStop_within_350m               BusStop_within_350m 1.281325e+12\n\n\n\nggplot(importance_df, aes(x = reorder(Feature, Importance), y = Importance)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  labs(title = \"Feature Importance for Random Forest Model (Ranger)\",\n       x = \"Features\",\n       y = \"Importance\")\n\n\n\n\n\n\n\n\nFeature importance analysis shows that the type of house, remaining lease time, distance to the CBD, floor and proximity to transportation hubs (such as MRT stations) have the greatest impact on HDB resale prices. Other living amenities have some impact on prices, but the effect is smaller."
  },
  {
    "objectID": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html#calibrating-geographical-random-forest-model",
    "href": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html#calibrating-geographical-random-forest-model",
    "title": "Take home Exercise03",
    "section": "8.Calibrating Geographical Random Forest Model",
    "text": "8.Calibrating Geographical Random Forest Model\n\nCalibrating using training data\nGeographically Weighted Random Forest optimal bandwidth selection: grf.bw-This function finds the optimal bandwidth for the Geographically Weighted Random Forest algo-rithm using an exhaustive approach.\n\noptimal_bw &lt;- grf.bw(\n  formula = resale_price ~ total_remaining_months +\n                  storey_mid + flat_model_numeric +\n                  flat_type_numeric + dist_to_elders + dist_to_hawkers +\n                  dist_to_parks + dist_to_supermarkets + dist_to_chas_clinics + \n                  dist_to_cbd + dist_to_Shoppingmalls +\n                  dist_to_MRT + dist_to_Goodprimaryschool +BusStop_within_350m+\n                  Kindergartens_within_1000m,\n  dataset = train_data,\n  kernel = \"adaptive\",\n  coords = coords_train,\n  bw.min = 30,      \n  bw.max = 100,     \n  step = 10,          \n  trees = 50,\n  nthreads = 8\n)\n\n\nFrom the result,we can get the best bandwidth 100 and we use this value for Geographical Random Forest Model analysis.\n\nsaveRDS(optimal_bw, \"data/rds/optimal_bw.rds\")\n\n\noptimal_bw &lt;- readRDS(\"data/rds/optimal_bw.rds\")\n\nThe code chunk below calibrate a geographic ranform forest model by using grf() of SpatialML package.\n\nset.seed(1234)\ngwRF_adaptive &lt;- grf(formula = resale_price ~ total_remaining_months +\n                  storey_mid + flat_model_numeric +\n                  flat_type_numeric + dist_to_elders + dist_to_hawkers +\n                  dist_to_parks + dist_to_supermarkets + dist_to_chas_clinics + \n                  dist_to_cbd + dist_to_Shoppingmalls +\n                  dist_to_MRT + dist_to_Goodprimaryschool +BusStop_within_350m+\n                  Kindergartens_within_1000m,\n                     dframe=train_data, \n                     bw=optimal_bw, \n                     kernel=\"adaptive\",\n                     coords=coords_train)\n\n\nGlobal ResultLocal ResultData.frame\n\n\n\n\nOOB prediction error (MSE): 1350504111, this is the out-of-bag mean square error (MSE) of the model, which measures the prediction error of the model.\nR squared (OOB): 0.9427949, the value of out-of-bag data, close to 1, indicating that the model has a high explanatory power on out-of-bag data.\nFlat_type_numeric and total_remaining_months have the highest importance scores, indicating that these variables have a greater impact on predicting the price of second-hand houses.\nStorey_mid and dist_to_cbd also have high importance, which may indicate that the floor of the house and the distance from the city center are also factors that determine the price.\nOther variables (such as dist_to_elders, dist_to_hawkers, dist_to_parks, etc.) also contribute to the prediction, but their importance is lower.\n\n\n\n\nThe model shows high explanatory power on the out-of-bag data (value of R squared 90.414%), but the out-of-bag mean squared error is relatively high, indicating that there may be some generalization error.\nThe model performs very well on the training data, with an almost perfect fit (value R squared close to 100%), but this may also indicate that the model is at risk of overfitting the training data.\n\n\n\n\nDescriptive statistics of the 15 variables in the dataframe, including minimum value (Min), maximum value (Max), mean (Mean), and standard deviation (Std)\n\n\n\n\nsaveRDS(gwRF_adaptive, \"data/rds/gwRF_adaptive.rds\")\n\n\ngwRF_adaptive &lt;- readRDS(\"data/rds/gwRF_adaptive.rds\")"
  },
  {
    "objectID": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html#predicting-by-using-test-data",
    "href": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html#predicting-by-using-test-data",
    "title": "Take home Exercise03",
    "section": "9.Predicting by using test data",
    "text": "9.Predicting by using test data\nMultiple linear regression model\n\nmlr_pred &lt;- predict(price_mlr, test_data_no)\n\nRandom Forest Model\n\nrf_pred &lt;- predict(rf,test_data_no)\n\nGeographical Random Forest Model\nPreparing the test data\n\ntest_data_n &lt;- cbind(test_data, coords_test) %&gt;%\n  st_drop_geometry()\n\nNext, predict.grf() of spatialML package will be used to predict the resale value by using the test data and gwRF_adaptive model calibrated earlier.\n\ngwRF_pred &lt;- predict.grf(gwRF_adaptive, \n                           test_data_n, \n                           x.var.name=\"X\",\n                           y.var.name=\"Y\", \n                           local.w=1,\n                           global.w=0)\n\n\nsaveRDS(gwRF_pred, \"data/rds/gwRF_pred.rds\")\n\n\ngwRF_pred &lt;- readRDS(\"data/rds/gwRF_pred.rds\")\n\nConverting the predicting output into a data frame\nThe output of the predict.grf() is a vector of predicted values. It is wiser to convert it into a data frame for further visualisation and analysis.\n\nGwRF_pred_df &lt;- as.data.frame(gwRF_pred)\n\n\nmlr_pred_df &lt;- as.data.frame(mlr_pred)\n\n\nrf_pred_df &lt;- as.data.frame(rf_pred)"
  },
  {
    "objectID": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html#visualising-the-predicted-values",
    "href": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html#visualising-the-predicted-values",
    "title": "Take home Exercise03",
    "section": "10.Visualising the predicted values",
    "text": "10.Visualising the predicted values\nRename columns\n\ncolnames(GwRF_pred_df) &lt;- \"gwRF_pred\"\ncolnames(mlr_pred_df) &lt;- \"mlr_pred\"\ncolnames(rf_pred_df) &lt;- \"rf_pred\"\n\nBind the prediction result column to the test data\n\ntest_data_pred &lt;- cbind(test_data[\"resale_price\"], mlr_pred_df, rf_pred_df, GwRF_pred_df)\n\nThis allows us to visually see the actual value of each data point and the predicted values ​​of different models arranged together in the same table\n\nprint(test_data_pred)\n\nSimple feature collection with 2359 features and 4 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 16408.86 ymin: 30188.16 xmax: 42444.73 ymax: 47860.87\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n   resale_price mlr_pred  rf_pred gwRF_pred                  geometry\n1        368000 413372.3 380866.0  493909.7 POINT (16505.05 36963.29)\n2        305000 500539.6 395622.1  461752.8  POINT (17261.37 36026.8)\n3        350000 446776.9 400633.5  461373.3 POINT (17256.96 36148.69)\n4        327000 398286.7 396987.1  483943.3 POINT (17659.32 36293.26)\n5        310000 330784.9 345153.6  510994.7  POINT (18441.84 33475.1)\n6        450000 572783.2 488658.9  512185.2  POINT (17396.62 35792.5)\n7        500000 572889.2 561440.2  494024.9 POINT (17911.43 35623.18)\n8        450000 541509.1 485654.9  517545.5 POINT (17659.29 36293.22)\n9        410000 371924.5 438132.9  499850.1 POINT (18421.09 33593.78)\n10       500000 505186.0 492564.3  505009.4 POINT (17368.73 33925.16)"
  },
  {
    "objectID": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html#calculating-root-mean-square-error",
    "href": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html#calculating-root-mean-square-error",
    "title": "Take home Exercise03",
    "section": "11.Calculating Root Mean Square Error",
    "text": "11.Calculating Root Mean Square Error\nRMSE represents the average deviation between the predicted value and the actual value. The unit is the same as the original data, so it can directly reflect the magnitude of the prediction error. The smaller the error, the lower the RMSE value, indicating that the model prediction is more accurate.\n\nrmse_mlr &lt;- rmse(test_data_pred$resale_price, test_data_pred$mlr_pred)\n\nrmse_rf &lt;- rmse(test_data_pred$resale_price, test_data_pred$rf_pred)\n\nrmse_gwRF &lt;- rmse(test_data_pred$resale_price, test_data_pred$gwRF_pred)"
  },
  {
    "objectID": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html#model-comparison",
    "href": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html#model-comparison",
    "title": "Take home Exercise03",
    "section": "12.Model comparison",
    "text": "12.Model comparison\n\nprint(data.frame(\n  Model = c(\"Multiple Linear Regression\",\"Random Forest\",\"Geographically Weighted Random Forest\"),\n  RMSE = c(rmse_mlr, rmse_rf,rmse_gwRF)\n))\n\n                                  Model      RMSE\n1            Multiple Linear Regression  74500.39\n2                         Random Forest  41600.14\n3 Geographically Weighted Random Forest 135184.74\n\n\nRandom Forest:\nRMSE = 41875.56 .The Random Forest model performs best among the three models, with the smallest RMSE value, indicating that its prediction results are closest to the actual values.\nMultiple Linear Regression:\nRMSE = 74505.25. The Multiple Linear Regression model performs second, with a higher RMSE value than the Random Forest, indicating that its prediction accuracy is lower than that of the Random Forest.\nGeographically Weighted Random Forest (GWRF):\nRMSE = 135184.74 .The Geographically Weighted Random Forest model has the largest RMSE value, which is much higher than the other two models, indicating that its prediction effect is the worst on this dataset.\n\n#After confirming the test_data_pred data frame structure, run pivot_longer()\ntest_data_long &lt;- test_data_pred %&gt;%\n  pivot_longer(cols = c(\"mlr_pred\", \"rf_pred\",\"gwRF_pred\"), \n               names_to = \"Model\", \n               values_to = \"Predicted\")\n\n\n#Using ggplot2 to draw faceted scatter plots\nggplot(data = test_data_long, aes(x = Predicted, y = resale_price)) +\n  geom_point(alpha = 0.6) +\n  facet_wrap(~ Model, scales = \"free\") +\n  theme_minimal() +\n  labs(title = \"Model Predictions vs Actual Resale Prices\",\n       x = \"Predicted Resale Price\",\n       y = \"Actual Resale Price\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nA better predictive model should have the scatter point close to the diagonal line. The scatter plot can be also used to detect if any outliers in the model.\n\n\nGeographically Weighted Random Forest (gwRF_pred): Most of the data points are concentrated near the diagonal, but there are some points that deviate from the diagonal, especially in the area of ​​high predicted values. Overall, the model is able to capture the trend of price changes, but the accuracy may be lacking in some intervals.\nMultiple Linear Regression (mlr_pred): The distribution of predicted values ​​and actual values ​​is relatively even, but there are some points that deviate from the diagonal, especially in the high price range. This model shows a linear trend, but seems to be biased towards high prices.\nRandom Forest (rf_pred): The relationship between the predicted values ​​and actual values ​​of this model is close to the diagonal, and most of the points are distributed near the diagonal, indicating that the model is relatively accurate in predicting high and low price data. The random forest model seems to capture more price details and performs best.\nSo,we finally choose Random Forest Model to predict our future price."
  },
  {
    "objectID": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html#predict-hdb-resale-prices-between-july-september-2024",
    "href": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html#predict-hdb-resale-prices-between-july-september-2024",
    "title": "Take home Exercise03",
    "section": "13.Predict HDB resale prices between July-September 2024",
    "text": "13.Predict HDB resale prices between July-September 2024\nWe apply the same method to predict the price from July to September in 2024.\n\nrf_pred_futre &lt;- predict(rf,resale_tidy6_future_test_data)\n\n\nrf_pred_futre_df &lt;- as.data.frame(rf_pred_futre)\n\n\npred_futre &lt;- cbind(resale_tidy6_future[\"resale_price\"], rf_pred_futre_df)\n\n\nprint(pred_futre)\n\nSimple feature collection with 2056 features and 2 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 16494.75 ymin: 30188.18 xmax: 42444.73 ymax: 47860.83\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n   resale_price prediction                  geometry\n1        530000   567742.6 POINT (17874.95 35907.07)\n2        500000   502437.2 POINT (17874.88 35907.03)\n3        418000   381793.1 POINT (16505.04 36963.21)\n4        510000   502310.3 POINT (17874.99 35907.04)\n5        390000   373551.8 POINT (16494.76 36917.38)\n6        531000   511753.6    POINT (17875 35907.09)\n7        410000   367047.7 POINT (16494.75 36917.32)\n8        465000   498615.2 POINT (17874.96 35907.06)\n9        390000   388659.6 POINT (17416.44 35364.49)\n10       405888   375368.9  POINT (17479.6 35465.57)\n\n\nNow we can clearly see the result and the comparison with the actual value."
  },
  {
    "objectID": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html#conclusion",
    "href": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html#conclusion",
    "title": "Take home Exercise03",
    "section": "14.Conclusion",
    "text": "14.Conclusion\nModel performance\nModel performance Random Forest: The random forest model performed best among all models with the smallest RMSE value. This shows that the prediction results of the random forest model are closest to the actual values ​​and have high prediction accuracy.\nMultiple Linear Regression: The RMSE value of the multiple linear regression model is higher than that of the random forest model, indicating that its prediction effect is not as good as the random forest model. Although the multiple linear regression model can better reveal the linear relationship of the data, it may be limited on complex data sets.\nGeographically Weighted Random Forest (GWRF): The GWRF model has the highest RMSE value, which is much higher than the other two models, indicating that its prediction effect is the worst on this data set. The GWRF model introduced geographical weights, but failed to effectively improve the prediction effect in this data set. This may be because the role of geographical factors is not significant, and the model parameters for example the trees,the steps and the range in optimal bandwidth need further optimization.\nFeature Importance Analysis\nIn terms of feature importance, variables such as flat type (flat_type_numeric), remaining lease months (total_remaining_months), and distance to the central business district (dist_to_cbd) have high importance in all models. This indicates that these factors are crucial in predicting HDB resale prices."
  },
  {
    "objectID": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html#reference",
    "href": "Take_home_Ex/Take_home_Ex03/Take_home_Ex03.html#reference",
    "title": "Take home Exercise03",
    "section": "15.Reference",
    "text": "15.Reference\nKam, T. S. (2024). 14 Geographically Weighted Predictive Models. R for Geospatial Data Science and Analytics.\nKalogiou, S., & Georganos, S. (2024). SpatialML: Spatial Machine Learning (Version 0.1.7) [Computer software]. https://stamatisgeoai.eu/"
  },
  {
    "objectID": "In-class_EX/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_EX/In-class_Ex02/In-class_Ex02.html",
    "title": "In-class_Ex02",
    "section": "",
    "text": "maptools is retired and binary is removed from CRAN. However, we can download from Posit Public Package Manager snapshots by using the code chunk below.\nAfter the installation is completed, it is important to edit the code chunk as shown below in order to avoid maptools being download and install repetitively every time the Quarto document been rendered.\ninstall.packages(\"maptools\", \n                 repos = \"https://packagemanager.posit.co/cran/2023-09-13\")\nIn sf package, there are two functions allow us to combine multiple simple features into one simple features. They are st_combine() and st_union().\npacman::p_load(tidyverse,sf,tmap,ggstatsplot,maptools)\nThe code chunk below, st_union()is used to derive the coastal outline sf tibble data.frame.\nsg_sf &lt;- mpsz_sf %&gt;%\n    st_union()\nThe code chunk below re-scale the unit of measurement from metre to kilometre before performing KDE.\npar(bg = \"#E4D5C9\")\n\ngridded_kde_childcareSG_ad &lt;- maptools::as.SpatialGridDataFrame.im(\n  kde_childcareSG_adaptive\n)\n\nspplot(gridded_kde_childcareSG_ad)\n# Spatstat.geom method\ngridded_kde_childcareSG_ad &lt;- as(\n  kde_childcareSG_adaptive, \n  \"SpatialGridDataFrame\"\n)\n\nspplot(gridded_kde_childcareSG_ad)\nset.seed(1234)\nMake sure the result is constant.\npacman::p_load(tidyverse,sf,tmap,ggstatsplot)"
  },
  {
    "objectID": "In-class_EX/In-class_Ex02/In-class_Ex02.html#importing-traffic-accident-data",
    "href": "In-class_EX/In-class_Ex02/In-class_Ex02.html#importing-traffic-accident-data",
    "title": "In-class_Ex02",
    "section": "Importing Traffic Accident Data",
    "text": "Importing Traffic Accident Data\n\nrdacc_sf &lt;- read_csv(\"data/thai_road_accident_2019_2022.csv\") %&gt;%\n  filter(!is.na(longitude) & longitude != \"\" & !is.na(latitude) & latitude != \"\") %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"),\n           crs=4326) %&gt;%\n  st_transform(crs = 32647)"
  },
  {
    "objectID": "In-class_EX/In-class_EX03/In-class_EX03.html",
    "href": "In-class_EX/In-class_EX03/In-class_EX03.html",
    "title": "In-class exercise 3",
    "section": "",
    "text": "pacman::p_load(sf, spNetwork, tmap, tidyverse)\n\n\nchildcare2 &lt;- st_read(dsn=\"data/rawdata\", layer=\"Punggol_CC\") %&gt;%\n  st_zm(drop = TRUE,\n        what = \"ZM\")\n\nReading layer `Punggol_CC' from data source \n  `/Users/yangyayong/Downloads/学校文件/smu文件/Term 3/G/yyyirene/ISSS626-GAA/In-class_EX/In-class_EX03/data/rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\n\n\n\nnetwork &lt;- st_read(dsn=\"data/rawdata\", \n                   layer=\"Punggol_St\")\n\nReading layer `Punggol_St' from data source \n  `/Users/yangyayong/Downloads/学校文件/smu文件/Term 3/G/yyyirene/ISSS626-GAA/In-class_EX/In-class_EX03/data/rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\n\n\n\nplot(network)\nplot(childcare2,add=T,col='red',pch = 19)\n\n\n\n\n\n\n\n\nwhich mean x,y\nNetwork: This object is typically a geographic spatial dataset that may contain geometric and attribute data for roads or other network structures.\nSt_geometry (network): This function extracts geometric data (such as coordinate points, lines, or polygons) from the network object for drawing or performing spatial operations.\n\ntmap_mode('plot')  # view is interactive\n\ntmap mode set to plotting\n\ntm_shape(childcare2) +\n\n tm_dots(col = \"red\") +  #keep the size constant for zoom in and zoom out\n\n tm_shape(network) +\n\n tm_lines()\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\n\nlixels &lt;- lixelize_lines(network, \n                         700, \n                         mindist = 375)\n\n\nkfun_childcare &lt;- kfunctions(network, \n                             childcare,\n                             start = 0, \n                             end = 1000, \n                             step = 50, \n                             width = 50, \n                             nsim = 50, #49\n                             resolution = 50,\n                             verbose = FALSE, \n                             conf_int = 0.05)\n\n\nkfun_childcare$plotk\n\nkfun_childcare$plotg\n\n\nacc &lt;- read_csv(\"data/rawdata/thai_road_accident_2019_2022.csv\") %&gt;%\n  mutate(Month_num = month(incident_datetime)) %&gt;%\n  mutate(Month_fac = month(incident_datetime, label = TRUE, abbr = TRUE)) %&gt;%\n  mutate(dayofweek = day(incident_datetime)) %&gt;%\n  filter(!is.na(longitude) & longitude != \"\", \n         !is.na(latitude) & latitude != \"\") %&gt;%  # 确保用 %&gt;% 连接 st_as_sf\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326) %&gt;%\n  st_transform(crs = 32647)\n\nRows: 81735 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (10): province_th, province_en, agency, route, vehicle_type, presumed_c...\ndbl   (6): acc_code, number_of_vehicles_involved, number_of_fatalities, numb...\ndttm  (2): incident_datetime, report_datetime\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nwrite_rds(acc,\"data/rds/acc.rds\")\n\n\nacc &lt;- read_rds(\"data/rds/acc.rds\")"
  }
]